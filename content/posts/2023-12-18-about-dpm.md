---
title: "About Deep Unsupervised Learning Using Nonequilibrium Thermodynamics"
date: 2023-12-18T18:06:41+01:00
draft: true

# cover:
#     image: "<image path/url>"
#     # can also paste direct link from external site
#     # ex. https://i.ibb.co/K0HVPBd/paper-mod-profilemode.png
#     alt: "<alt text>"
#     caption: "<text>"
#     relative: false # To use relative path for cover image, used in hugo Page-bundles

tags: ["diffusion", "ai", "dpm", "model", "probabilistic", "nonequilibrium", "thermodynamics", "Markov chain", "Gaussian"]

ShowToc: true
---

***Disclaimer:*** *This is part of my notes on AI research papers. I do this to learn and communicate what I understand. Feel free to comment if you have any suggestion, that would be very much appreciated.*

The following post is a summary of the paper [Deep Unsupervised Learning using Nonequilibrium Thermodynamics](https://arxiv.org/pdf/1503.03585.pdf) by [Jascha Sohl-Dickstein](), [Eric A. Weiss](), [Niru Maheswaranathan]() and [Surya Ganguli](). The paper was published in 2015 and it is the first one to introduce the concept of Diffusion Probabilistic Models (DPMs). 

By that time, probabilistic models suffered from a conflicting trade-off between *tractability* and *flexibility*. 
- Tractable models are those that can be analytically evaluated and easily fit to data. However, they are not flexible enough to capture complex distributions.
- Flexible models can fit the structure of any distribution but they are hard to train, evaluate and sample from.

They proposed Diffusion Probabilistic Models as a new family of probabilistic models that tackle this dichotomy and claim  that DPMs allow:
1. Extreme flexibility in model structure.
2. Exact sampling.
3. Easy multiplication with other distributions.
4. Cheap evaluation of the log likelihood and probability of individual states.

## Diffusion Probabilistic Models
<!-- The method is based on an idea from non-equilibrium statistical physics ([Jarzynski, 1997]()(see https://www.youtube.com/watch?v=LXcQx6Bu3OQ)) and sequential Monte Carlo ([Neal 2001]) -->
The method is based on the idea of using a Markov chain to *gradualy* transform one distribution into another. In particular, they build a Markov chain which converts a simple known distribution, for instance a Gaussian, into the target complex data distribution using a *diffusion process*. Thus, learning involves estimating small perturbations within this process, which are more tractable than explicitly modeling the target distribution with a single intricate function.

----- add image here -----
caption: animation of a diffusion process, from a complex distribution to a simple one.


### Algorithm
The algorithm is defined as a two-step process, the *forward trajectory* and the *reverse trajectory*.

#### Forward trajectory
Let us assume that the distribution of our data is $q(\textbf{x}^{(0)})$. During this first stage, the algorithm will gradually transform $q(\textbf{x}^{(0)})$ into a simple distribution $\pi(\textbf{y})$ by repeatingly applying a <u>Markov diffusion kernel</u>