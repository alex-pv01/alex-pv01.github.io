<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css integrity=sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js integrity=sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Attention and Context based Embeddings | Àlex</title>
<meta name=keywords content="Attention Mechanisms,Natural Language Processing,Deep Learning,Machine Translation,AI"><meta name=description content="Attention mechanisms are a type of techniques used in natural language processing (NLP) tasks that allow a model to focus on specific parts of the input when processing a sequence, rather than considering the entire sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.
<<<<<<< HEAD
To some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence."><meta name=author content="Àlex Pujol Vidal"><link rel=canonical href=http://localhost:1313/posts/articles/attention-mechanisms/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/articles/attention-mechanisms/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><!doctype html><html><head><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity=sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity=sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity=sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script></head>...</html><meta property="og:title" content="Attention and Context based Embeddings"><meta property="og:description" content="Attention mechanisms are a type of techniques used in natural language processing (NLP) tasks that allow a model to focus on specific parts of the input when processing a sequence, rather than considering the entire sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.
To some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/articles/attention-mechanisms/"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-17T17:51:02+01:00"><meta property="article:modified_time" content="2022-12-17T17:51:02+01:00"><meta property="og:site_name" content="Àlex' personal site"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Attention and Context based Embeddings"><meta name=twitter:description content="Attention mechanisms are a type of techniques used in natural language processing (NLP) tasks that allow a model to focus on specific parts of the input when processing a sequence, rather than considering the entire sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.
To some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Attention and Context based Embeddings","item":"http://localhost:1313/posts/articles/attention-mechanisms/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Attention and Context based Embeddings","name":"Attention and Context based Embeddings","description":"Attention mechanisms are a type of techniques used in natural language processing (NLP) tasks that allow a model to focus on specific parts of the input when processing a sequence, rather than considering the entire sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.\nTo some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence.","keywords":["Attention Mechanisms","Natural Language Processing","Deep Learning","Machine Translation","AI"],"articleBody":"Attention mechanisms are a type of techniques used in natural language processing (NLP) tasks that allow a model to focus on specific parts of the input when processing a sequence, rather than considering the entire sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.\nTo some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence. They were born to deal with long sequences in sequence-to-sequence tasks. That is, any problem that requieres a sequence as an input, and outputs another sequence. For example, in machine translation, attention mechanisms can allow the model to translate each word in the source language sentence one at a time, focusing on the most relevant words in the source sentence at each step. This can be especially important for tasks that involve long sentences, as it allows the model to better capture the meaning and context of the input.\nThey have become a key component of many other tasks, not only in machine translation but also in other problems such as summarization, and language modeling. They have been shown to improve the performance of various models and are an active area of research in the field.\nHow attention mechanisms work: Attention mechanisms are often implemented as part of a recurrent neural network (RNN) in a sequence-to-sequence model, is compossed by an encoder and a decoder:\nThe encoder is a RNN that processes the input sequence and compresses the information into a context vector. Such vector represents the whole input sequence and is expected to be a good summary of its meaning.\nThe decoder is another RNN that recieves the context vector and outputs a transformed vector that ideally solves the problem we are dealing with.\nBy construction of the RNNs the context vector has a fixed size an requires the implementation of an attentenion mechanism to deal with long sequences, since otherwise the model “forgets” information.\nIn a broad sense, the seq2seq model processes the input sequence one element at a time. At each step, the attention mechanism calculates the weights for each element in the input sequence based on their relevance to the current state of the model. The weights can be calculated using various similarity measures, such as the dot product between the current state of the model and each element in the input sequence.\nMore formally, consider we have an input sequence $\\textbf{x}$ of lenght $n$ and that we want to output a target sequence $\\textbf{y}$ of lenght $m$,\n\\begin{align} \\textbf{x} = [x_1, \\dots, x_n] \\\\ \\textbf{y} = [y_1, \\dots, y_m]. \\end{align}\nWe start by initializing the hidden state of encoder, which can be a random vector, $\\bar{\\textbf{h}}_0$. While the sequence is not finished, it takes as input, one element at a time from $\\textbf{x}$ and the previous hidden state. At each step it generates a new vector $\\bar{\\textbf{h}}_i$ called hidden state of the encoder at step $i$, for $i = 1, \\dots, n$. Notice that each $\\bar{\\textbf{h}}_i$ is presumably more associated with the element $x_i$. Once, all the hidden states are processed, they are sent to the decoder.\nThe decoder also has its hidden state initialized, $\\textbf{h}_0$. Then, it takes at each step $t$ a weighted combination of the encoder hidden states as a current context vector, the previous decoder’s hidden state and the previous element of the output sequence to predict the value $y_t$. That is, for $t=1,\\dots, m$, the decoder’s hidden state at $t+1$ is of the form $\\textbf{h}_{t+1} = f(\\textbf{h}_t, \\textbf{c}_{t+1}, y_t)$, where:\n\\begin{align} \\textbf{c}_t \u0026 = \\sum_{i=1}^n \\alpha_{t,i} \\bar{\\textbf{h}}_i \\quad \u0026; \\text{is the context vector at step }t. \\\\ \\alpha_{t+1,i} \u0026 = \\frac{\\exp(\\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_i))}{\\sum_{i'=1}^n\\exp(\\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_{i'}))} \\quad \u0026; \\text{softmaxed similarity score.} \\end{align}\nThe $\\text{score}$ function assigns a measure of similarity between hidden states. There are several ways to approach it, first introduced by Bahdanau, et al., 2014 and Luong, et al., 2015. For instance, one could use as a simple similarity function the dot product. The value $\\alpha_{t,i}$ aims to indicate the similarity between element $y_t$ and $x_i$.\nFinally, in order to predict the value $\\textbf{y}_t$, the model concatenates the hidden layer $\\textbf{h}_t$ and the context vector $\\textbf{c}_t$, and pass them through a feedforward neural network that is trained simultaneously. This process is then repited until the completion of the output sequence.\nBahdanau attention: Bahdanau attention, also known as additive attention, is a type of attention mechanism that was introduced in a 2014 paper by Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. It is widely used and has been shown to improve the performance of several models regarding NLP tasks.\nIt is introduced in the previous model by defining the following $\\text{score}$ function:\n$$ \\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_i) = \\textbf{v}_a^T \\cdot \\text{tanh}(\\textbf{W}_a \\cdot [ \\textbf{h}_t ; \\bar{\\textbf{h}}_i ]) $$\nwhere $\\textbf{v}_a$ and $\\textbf{W}_a$ are weighted matrices to be learned in the training process. They can be implemented as dense layers using keras. For a python implementation of the Bahnadau attention mechanism one can be refered to the following Notebook.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class BahdanauAttention(tf.keras.layers.Layer): def __init__(self, units): super(BahdanauAttention, self).__init__() self.W1 = tf.keras.layers.Dense(units) self.W2 = tf.keras.layers.Dense(units) self.V = tf.keras.layers.Dense(1) def call(self, query, values): query_with_time_axis = tf.expand_dims(query, 1) # BAHDANAU Additive score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values))) # attention_weights shape == (batch_size, max_length, 1) attention_weights = tf.nn.softmax(score, axis=1) # context_vector shape after sum == (batch_size, hidden_size) context_vector = attention_weights * values context_vector = tf.reduce_sum(context_vector, axis=1) return context_vector, attention_weights Luong attention: Luong attention, introduced in a 2015 paper by Minh-Thang Luong et al., is a variant of Bahdanau attention that uses different similarity measures to calculate the attention weights.\nOne common variant is dot-product attention, which calculates the attention weights as the dot product between the current state of the model and each element in the input sequence. That is,\n$$ \\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_i) = \\textbf{h}_t^T \\cdot \\bar{\\textbf{h}}_i $$\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class LuongDotAttention(tf.keras.layers.Layer): def __init__(self): super(LuongDotAttention, self).__init__() def call(self, query, values): query_with_time_axis = tf.expand_dims(query, 1) values_transposed = tf.transpose(values, perm=[0, 2, 1]) # LUONG Dot-product score = tf.transpose(tf.matmul(query_with_time_axis, values_transposed), perm=[0, 2, 1]) # attention_weights shape == (batch_size, max_length, 1) attention_weights = tf.nn.softmax(score, axis=1) # context_vector shape after sum == (batch_size, hidden_size) context_vector = attention_weights * values context_vector = tf.reduce_sum(context_vector, axis=1) return context_vector, attention_weights Another variant is general attention, which implements the attention weights $\\textbf{W}_a$ using a general linear function.\n$$ \\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_i) = \\textbf{h}_t^T \\cdot \\textbf{W}_a \\cdot \\bar{\\textbf{h}}_i $$\nSuch $\\textbf{W}_a$ matrix is also to be learned during the training process. For a python implementation of the Luong attention mechanisms one can be refered to the following Notebook.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class LuongGeneralAttention(tf.keras.layers.Layer): def __init__(self, units): super(LuongGeneralAttention, self).__init__() self.W = tf.keras.layers.Dense(units) def call(self, query, values): query_with_time_axis = tf.expand_dims(query, 1) values_transposed = tf.transpose(values, perm=[0, 2, 1]) # LUONG General score = tf.transpose(tf.matmul(self.W(query_with_time_axis), values_transposed), perm=[0, 2, 1]) # attention_weights shape == (batch_size, max_length, 1) attention_weights = tf.nn.softmax(score, axis=1) # context_vector shape after sum == (batch_size, hidden_size) context_vector = attention_weights * values context_vector = tf.reduce_sum(context_vector, axis=1) return context_vector, attention_weights Limitations of attention mechanisms: While attention mechanisms have been shown to be effective in many NLP tasks, they do have some limitations:\nComputational intensity: Attention mechanisms can be computationally intensive, especially for large input sequences. This can make them difficult to train and use in practice, for instance on large datasets.\nLimited ability to capture long-range dependencies: Attention mechanisms can struggle to accurately capture long-range dependencies in the input, as they only consider the current state of the model and the input elements when calculating the attention weights. This can lead to suboptimal performance on tasks that require the model to consider the relationship between distant elements in the input sequence.\nLimited interpretability: Attention mechanisms can be difficult to interpret, as it is often not clear how the attention weights are being calculated or how they are influencing the model’s predictions. This can make it difficult to understand the decision-making process of the model and debug any errors.\nLimited generalizability: Attention mechanisms may not generalize well to new data, as they are trained on specific datasets and may not be able to adapt to different input distributions.\nConclusion: Overall, attention mechanisms have many strengths and have been shown to be effective in many NLP tasks. However, it is important to be aware of their limitations and to carefully consider whether they are the best approach for a particular task. Having said so, attention mechanisms are an active area of research in NLP and there are many potential directions for future development. These developments could lead to more efficient, accurate, interpretable, and generalizable attention mechanisms, which could further improve the performance of NLP models and enable them to solve more complex tasks.\n","wordCount":"1515","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2022-12-17T17:51:02+01:00","dateModified":"2022-12-17T17:51:02+01:00","author":{"@type":"Person","name":"Àlex Pujol Vidal"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/articles/attention-mechanisms/"},"publisher":{"@type":"Organization","name":"Àlex","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Àlex (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Àlex</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=about><span>about</span></a></li><li><a href=http://localhost:1313/archives/ title=archives><span>archives</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://www.countop.com/ title=countop.com><span>countop.com</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Attention and Context based Embeddings</h1><div class=post-meta><span title='2022-12-17 17:51:02 +0100 CET'>December 17, 17175</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Àlex Pujol Vidal&nbsp;|&nbsp;<a href=https://github.com/alex-pv01/alex-pv01.github.io/tree/main/content/posts/articles/attention-mechanisms.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#how-attention-mechanisms-work>How attention mechanisms work:</a></li><li><a href=#bahdanau-attention>Bahdanau attention:</a></li><li><a href=#luong-attention>Luong attention:</a></li><li><a href=#limitations-of-attention-mechanisms>Limitations of attention mechanisms:</a></li><li><a href=#conclusion>Conclusion:</a></li></ul></nav></div></details></div><div class=post-content><p><strong>Attention mechanisms</strong> are a type of techniques used in <strong>natural language processing (NLP)</strong> tasks that allow a model to focus on <strong>specific</strong> parts of the input when processing a sequence, rather than considering the <strong>entire</strong> sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.</p><p>To some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence. They were born to deal with long sequences in <strong>sequence-to-sequence</strong> tasks. That is, any problem that requieres a sequence as an input, and outputs another sequence. For example, in machine translation, attention mechanisms can allow the model to translate each word in the source language sentence one at a time, focusing on the most relevant words in the source sentence at each step. This can be especially important for tasks that involve long sentences, as it allows the model to better capture the <strong>meaning and context</strong> of the input.</p><p>They have become a key component of many other tasks, not only in machine translation but also in other problems such as summarization, and language modeling. They have been shown to improve the performance of various models and are an active area of research in the field.</p><h2 id=how-attention-mechanisms-work>How attention mechanisms work:<a hidden class=anchor aria-hidden=true href=#how-attention-mechanisms-work>#</a></h2><p>Attention mechanisms are often implemented as part of a <strong>recurrent neural network (RNN)</strong> in a sequence-to-sequence model, is compossed by an <strong>encoder</strong> and a <strong>decoder</strong>:</p><ul><li><p>The <strong>encoder</strong> is a RNN that processes the input sequence and compresses the information into a <strong>context vector</strong>. Such vector represents the whole input sequence and is expected to be a good summary of its meaning.</p></li><li><p>The <strong>decoder</strong> is another RNN that recieves the context vector and outputs a transformed vector that ideally solves the problem we are dealing with.</p></li></ul><p>By construction of the RNNs the context vector has a fixed size an requires the implementation of an attentenion mechanism to deal with long sequences, since otherwise the model &ldquo;forgets&rdquo; information.</p><p>In a broad sense, the seq2seq model processes the input sequence one element at a time. At each step, the attention mechanism calculates the <strong>weights</strong> for each element in the input sequence based on their relevance to the current state of the model. The weights can be calculated using various similarity measures, such as the dot product between the current state of the model and each element in the input sequence.</p><p>More formally, consider we have an input sequence $\textbf{x}$ of lenght $n$ and that we want to output a target sequence $\textbf{y}$ of lenght $m$,</p><p>\begin{align}
=======
To some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence."><meta name=author content="Àlex Pujol Vidal"><link rel=canonical href=https://alex-pv01.github.io/posts/articles/attention-mechanisms/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://alex-pv01.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://alex-pv01.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://alex-pv01.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://alex-pv01.github.io/apple-touch-icon.png><link rel=mask-icon href=https://alex-pv01.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://alex-pv01.github.io/posts/articles/attention-mechanisms/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><!doctype html><html><head><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity=sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity=sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity=sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script></head>...</html><meta property="og:title" content="Attention and Context based Embeddings"><meta property="og:description" content="Attention mechanisms are a type of techniques used in natural language processing (NLP) tasks that allow a model to focus on specific parts of the input when processing a sequence, rather than considering the entire sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.
To some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence."><meta property="og:type" content="article"><meta property="og:url" content="https://alex-pv01.github.io/posts/articles/attention-mechanisms/"><meta property="og:image" content="https://alex-pv01.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-17T17:51:02+01:00"><meta property="article:modified_time" content="2022-12-17T17:51:02+01:00"><meta property="og:site_name" content="Àlex' personal site"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://alex-pv01.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Attention and Context based Embeddings"><meta name=twitter:description content="Attention mechanisms are a type of techniques used in natural language processing (NLP) tasks that allow a model to focus on specific parts of the input when processing a sequence, rather than considering the entire sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.
To some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://alex-pv01.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Attention and Context based Embeddings","item":"https://alex-pv01.github.io/posts/articles/attention-mechanisms/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Attention and Context based Embeddings","name":"Attention and Context based Embeddings","description":"Attention mechanisms are a type of techniques used in natural language processing (NLP) tasks that allow a model to focus on specific parts of the input when processing a sequence, rather than considering the entire sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.\nTo some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence.","keywords":["Attention Mechanisms","Natural Language Processing","Deep Learning","Machine Translation","AI"],"articleBody":"Attention mechanisms are a type of techniques used in natural language processing (NLP) tasks that allow a model to focus on specific parts of the input when processing a sequence, rather than considering the entire sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.\nTo some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence. They were born to deal with long sequences in sequence-to-sequence tasks. That is, any problem that requieres a sequence as an input, and outputs another sequence. For example, in machine translation, attention mechanisms can allow the model to translate each word in the source language sentence one at a time, focusing on the most relevant words in the source sentence at each step. This can be especially important for tasks that involve long sentences, as it allows the model to better capture the meaning and context of the input.\nThey have become a key component of many other tasks, not only in machine translation but also in other problems such as summarization, and language modeling. They have been shown to improve the performance of various models and are an active area of research in the field.\nHow attention mechanisms work: Attention mechanisms are often implemented as part of a recurrent neural network (RNN) in a sequence-to-sequence model, is compossed by an encoder and a decoder:\nThe encoder is a RNN that processes the input sequence and compresses the information into a context vector. Such vector represents the whole input sequence and is expected to be a good summary of its meaning.\nThe decoder is another RNN that recieves the context vector and outputs a transformed vector that ideally solves the problem we are dealing with.\nBy construction of the RNNs the context vector has a fixed size an requires the implementation of an attentenion mechanism to deal with long sequences, since otherwise the model “forgets” information.\nIn a broad sense, the seq2seq model processes the input sequence one element at a time. At each step, the attention mechanism calculates the weights for each element in the input sequence based on their relevance to the current state of the model. The weights can be calculated using various similarity measures, such as the dot product between the current state of the model and each element in the input sequence.\nMore formally, consider we have an input sequence $\\textbf{x}$ of lenght $n$ and that we want to output a target sequence $\\textbf{y}$ of lenght $m$,\n\\begin{align} \\textbf{x} = [x_1, \\dots, x_n] \\\\ \\textbf{y} = [y_1, \\dots, y_m]. \\end{align}\nWe start by initializing the hidden state of encoder, which can be a random vector, $\\bar{\\textbf{h}}_0$. While the sequence is not finished, it takes as input, one element at a time from $\\textbf{x}$ and the previous hidden state. At each step it generates a new vector $\\bar{\\textbf{h}}_i$ called hidden state of the encoder at step $i$, for $i = 1, \\dots, n$. Notice that each $\\bar{\\textbf{h}}_i$ is presumably more associated with the element $x_i$. Once, all the hidden states are processed, they are sent to the decoder.\nThe decoder also has its hidden state initialized, $\\textbf{h}_0$. Then, it takes at each step $t$ a weighted combination of the encoder hidden states as a current context vector, the previous decoder’s hidden state and the previous element of the output sequence to predict the value $y_t$. That is, for $t=1,\\dots, m$, the decoder’s hidden state at $t+1$ is of the form $\\textbf{h}_{t+1} = f(\\textbf{h}_t, \\textbf{c}_{t+1}, y_t)$, where:\n\\begin{align} \\textbf{c}_t \u0026 = \\sum_{i=1}^n \\alpha_{t,i} \\bar{\\textbf{h}}_i \\quad \u0026; \\text{is the context vector at step }t. \\\\ \\alpha_{t+1,i} \u0026 = \\frac{\\exp(\\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_i))}{\\sum_{i'=1}^n\\exp(\\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_{i'}))} \\quad \u0026; \\text{softmaxed similarity score.} \\end{align}\nThe $\\text{score}$ function assigns a measure of similarity between hidden states. There are several ways to approach it, first introduced by Bahdanau, et al., 2014 and Luong, et al., 2015. For instance, one could use as a simple similarity function the dot product. The value $\\alpha_{t,i}$ aims to indicate the similarity between element $y_t$ and $x_i$.\nFinally, in order to predict the value $\\textbf{y}_t$, the model concatenates the hidden layer $\\textbf{h}_t$ and the context vector $\\textbf{c}_t$, and pass them through a feedforward neural network that is trained simultaneously. This process is then repited until the completion of the output sequence.\nBahdanau attention: Bahdanau attention, also known as additive attention, is a type of attention mechanism that was introduced in a 2014 paper by Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. It is widely used and has been shown to improve the performance of several models regarding NLP tasks.\nIt is introduced in the previous model by defining the following $\\text{score}$ function:\n$$ \\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_i) = \\textbf{v}_a^T \\cdot \\text{tanh}(\\textbf{W}_a \\cdot [ \\textbf{h}_t ; \\bar{\\textbf{h}}_i ]) $$\nwhere $\\textbf{v}_a$ and $\\textbf{W}_a$ are weighted matrices to be learned in the training process. They can be implemented as dense layers using keras. For a python implementation of the Bahnadau attention mechanism one can be refered to the following Notebook.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class BahdanauAttention(tf.keras.layers.Layer): def __init__(self, units): super(BahdanauAttention, self).__init__() self.W1 = tf.keras.layers.Dense(units) self.W2 = tf.keras.layers.Dense(units) self.V = tf.keras.layers.Dense(1) def call(self, query, values): query_with_time_axis = tf.expand_dims(query, 1) # BAHDANAU Additive score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values))) # attention_weights shape == (batch_size, max_length, 1) attention_weights = tf.nn.softmax(score, axis=1) # context_vector shape after sum == (batch_size, hidden_size) context_vector = attention_weights * values context_vector = tf.reduce_sum(context_vector, axis=1) return context_vector, attention_weights Luong attention: Luong attention, introduced in a 2015 paper by Minh-Thang Luong et al., is a variant of Bahdanau attention that uses different similarity measures to calculate the attention weights.\nOne common variant is dot-product attention, which calculates the attention weights as the dot product between the current state of the model and each element in the input sequence. That is,\n$$ \\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_i) = \\textbf{h}_t^T \\cdot \\bar{\\textbf{h}}_i $$\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class LuongDotAttention(tf.keras.layers.Layer): def __init__(self): super(LuongDotAttention, self).__init__() def call(self, query, values): query_with_time_axis = tf.expand_dims(query, 1) values_transposed = tf.transpose(values, perm=[0, 2, 1]) # LUONG Dot-product score = tf.transpose(tf.matmul(query_with_time_axis, values_transposed), perm=[0, 2, 1]) # attention_weights shape == (batch_size, max_length, 1) attention_weights = tf.nn.softmax(score, axis=1) # context_vector shape after sum == (batch_size, hidden_size) context_vector = attention_weights * values context_vector = tf.reduce_sum(context_vector, axis=1) return context_vector, attention_weights Another variant is general attention, which implements the attention weights $\\textbf{W}_a$ using a general linear function.\n$$ \\text{score}(\\textbf{h}_t, \\bar{\\textbf{h}}_i) = \\textbf{h}_t^T \\cdot \\textbf{W}_a \\cdot \\bar{\\textbf{h}}_i $$\nSuch $\\textbf{W}_a$ matrix is also to be learned during the training process. For a python implementation of the Luong attention mechanisms one can be refered to the following Notebook.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class LuongGeneralAttention(tf.keras.layers.Layer): def __init__(self, units): super(LuongGeneralAttention, self).__init__() self.W = tf.keras.layers.Dense(units) def call(self, query, values): query_with_time_axis = tf.expand_dims(query, 1) values_transposed = tf.transpose(values, perm=[0, 2, 1]) # LUONG General score = tf.transpose(tf.matmul(self.W(query_with_time_axis), values_transposed), perm=[0, 2, 1]) # attention_weights shape == (batch_size, max_length, 1) attention_weights = tf.nn.softmax(score, axis=1) # context_vector shape after sum == (batch_size, hidden_size) context_vector = attention_weights * values context_vector = tf.reduce_sum(context_vector, axis=1) return context_vector, attention_weights Limitations of attention mechanisms: While attention mechanisms have been shown to be effective in many NLP tasks, they do have some limitations:\nComputational intensity: Attention mechanisms can be computationally intensive, especially for large input sequences. This can make them difficult to train and use in practice, for instance on large datasets.\nLimited ability to capture long-range dependencies: Attention mechanisms can struggle to accurately capture long-range dependencies in the input, as they only consider the current state of the model and the input elements when calculating the attention weights. This can lead to suboptimal performance on tasks that require the model to consider the relationship between distant elements in the input sequence.\nLimited interpretability: Attention mechanisms can be difficult to interpret, as it is often not clear how the attention weights are being calculated or how they are influencing the model’s predictions. This can make it difficult to understand the decision-making process of the model and debug any errors.\nLimited generalizability: Attention mechanisms may not generalize well to new data, as they are trained on specific datasets and may not be able to adapt to different input distributions.\nConclusion: Overall, attention mechanisms have many strengths and have been shown to be effective in many NLP tasks. However, it is important to be aware of their limitations and to carefully consider whether they are the best approach for a particular task. Having said so, attention mechanisms are an active area of research in NLP and there are many potential directions for future development. These developments could lead to more efficient, accurate, interpretable, and generalizable attention mechanisms, which could further improve the performance of NLP models and enable them to solve more complex tasks.\n","wordCount":"1515","inLanguage":"en","datePublished":"2022-12-17T17:51:02+01:00","dateModified":"2022-12-17T17:51:02+01:00","author":{"@type":"Person","name":"Àlex Pujol Vidal"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://alex-pv01.github.io/posts/articles/attention-mechanisms/"},"publisher":{"@type":"Organization","name":"Àlex","logo":{"@type":"ImageObject","url":"https://alex-pv01.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://alex-pv01.github.io/ accesskey=h title="Àlex (Alt + H)"><img src=https://alex-pv01.github.io/apple-touch-icon.png alt aria-label=logo height=35>Àlex</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://alex-pv01.github.io/about/ title=about><span>about</span></a></li><li><a href=https://alex-pv01.github.io/archives/ title=archives><span>archives</span></a></li><li><a href=https://alex-pv01.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://www.countop.com/ title=countop.com><span>countop.com</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Attention and Context based Embeddings</h1><div class=post-meta>&lt;span title='2022-12-17 17:51:02 +0100 CET'>December 17, 17175&lt;/span>&amp;nbsp;·&amp;nbsp;8 min&amp;nbsp;·&amp;nbsp;Àlex Pujol Vidal&nbsp;|&nbsp;<a href=https://github.com/alex-pv01/alex-pv01.github.io/tree/main/content/posts/articles/attention-mechanisms.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#how-attention-mechanisms-work>How attention mechanisms work:</a></li><li><a href=#bahdanau-attention>Bahdanau attention:</a></li><li><a href=#luong-attention>Luong attention:</a></li><li><a href=#limitations-of-attention-mechanisms>Limitations of attention mechanisms:</a></li><li><a href=#conclusion>Conclusion:</a></li></ul></nav></div></details></div><div class=post-content><p><strong>Attention mechanisms</strong> are a type of techniques used in <strong>natural language processing (NLP)</strong> tasks that allow a model to focus on <strong>specific</strong> parts of the input when processing a sequence, rather than considering the <strong>entire</strong> sequence at once. These methods can improve the performance of the model by allowing it to efficiently process long sequences of text and make more accurate predictions.</p><p>To some extend, attention mechanisms are motivated by how human visual attention focuses on different regions of an image or how correlates words in a sentence. They were born to deal with long sequences in <strong>sequence-to-sequence</strong> tasks. That is, any problem that requieres a sequence as an input, and outputs another sequence. For example, in machine translation, attention mechanisms can allow the model to translate each word in the source language sentence one at a time, focusing on the most relevant words in the source sentence at each step. This can be especially important for tasks that involve long sentences, as it allows the model to better capture the <strong>meaning and context</strong> of the input.</p><p>They have become a key component of many other tasks, not only in machine translation but also in other problems such as summarization, and language modeling. They have been shown to improve the performance of various models and are an active area of research in the field.</p><h2 id=how-attention-mechanisms-work>How attention mechanisms work:<a hidden class=anchor aria-hidden=true href=#how-attention-mechanisms-work>#</a></h2><p>Attention mechanisms are often implemented as part of a <strong>recurrent neural network (RNN)</strong> in a sequence-to-sequence model, is compossed by an <strong>encoder</strong> and a <strong>decoder</strong>:</p><ul><li><p>The <strong>encoder</strong> is a RNN that processes the input sequence and compresses the information into a <strong>context vector</strong>. Such vector represents the whole input sequence and is expected to be a good summary of its meaning.</p></li><li><p>The <strong>decoder</strong> is another RNN that recieves the context vector and outputs a transformed vector that ideally solves the problem we are dealing with.</p></li></ul><p>By construction of the RNNs the context vector has a fixed size an requires the implementation of an attentenion mechanism to deal with long sequences, since otherwise the model &ldquo;forgets&rdquo; information.</p><p>In a broad sense, the seq2seq model processes the input sequence one element at a time. At each step, the attention mechanism calculates the <strong>weights</strong> for each element in the input sequence based on their relevance to the current state of the model. The weights can be calculated using various similarity measures, such as the dot product between the current state of the model and each element in the input sequence.</p><p>More formally, consider we have an input sequence $\textbf{x}$ of lenght $n$ and that we want to output a target sequence $\textbf{y}$ of lenght $m$,</p><p>\begin{align}
>>>>>>> 3e41910ec3b37fbf49862f5d6edb1c57ce5467db
\textbf{x} = [x_1, \dots, x_n] \\
\textbf{y} = [y_1, \dots, y_m].
\end{align}</p><p>We start by <strong>initializing</strong> the hidden state of encoder, which can be a random vector, $\bar{\textbf{h}}_0$. While the sequence is not finished, it takes as input, one element at a time from $\textbf{x}$ and the previous hidden state. At each step it generates a new vector $\bar{\textbf{h}}_i$ called <strong>hidden state</strong> of the encoder at step $i$, for $i = 1, \dots, n$. Notice that each $\bar{\textbf{h}}_i$ is presumably more associated with the element $x_i$. Once, all the hidden states are processed, they are sent to the decoder.</p><p>The decoder also has its hidden state initialized, $\textbf{h}_0$. Then, it takes at each step $t$ a <strong>weighted</strong> combination of the encoder hidden states as a current <strong>context vector</strong>, the previous decoder&rsquo;s hidden state and the previous element of the output sequence to predict the value $y_t$. That is, for $t=1,\dots, m$, the decoder&rsquo;s hidden state at $t+1$ is of the form $\textbf{h}_{t+1} = f(\textbf{h}_t, \textbf{c}_{t+1}, y_t)$, where:</p><p>\begin{align}
\textbf{c}_t & = \sum_{i=1}^n \alpha_{t,i} \bar{\textbf{h}}_i \quad &; \text{is the context vector at step }t. \\
\alpha_{t+1,i} & = \frac{\exp(\text{score}(\textbf{h}_t, \bar{\textbf{h}}_i))}{\sum_{i'=1}^n\exp(\text{score}(\textbf{h}_t, \bar{\textbf{h}}_{i'}))} \quad &; \text{softmaxed similarity score.}
\end{align}</p><p>The $\text{score}$ function assigns a measure of similarity between hidden states. There are several ways to approach it, first introduced by <a href=https://arxiv.org/pdf/1409.0473.pdf>Bahdanau, et al., 2014</a> and <a href=https://arxiv.org/pdf/1508.04025.pdf>Luong, et al., 2015</a>. For instance, one could use as a simple similarity function the dot product. The value $\alpha_{t,i}$ aims to indicate the similarity between element $y_t$ and $x_i$.</p><p>Finally, in order to predict the value $\textbf{y}_t$, the model concatenates the hidden layer $\textbf{h}_t$ and the context vector $\textbf{c}_t$, and pass them through a feedforward neural network that is trained simultaneously. This process is then repited until the completion of the output sequence.</p><h2 id=bahdanau-attention>Bahdanau attention:<a hidden class=anchor aria-hidden=true href=#bahdanau-attention>#</a></h2><p><strong>Bahdanau attention</strong>, also known as additive attention, is a type of attention mechanism that was introduced in a 2014 <a href=https://arxiv.org/pdf/1409.0473.pdf>paper</a> by Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. It is widely used and has been shown to improve the performance of several models regarding NLP tasks.</p><p>It is introduced in the previous model by defining the following $\text{score}$ function:</p><p>$$ \text{score}(\textbf{h}_t, \bar{\textbf{h}}_i) = \textbf{v}_a^T \cdot \text{tanh}(\textbf{W}_a \cdot [ \textbf{h}_t ; \bar{\textbf{h}}_i ]) $$</p><p>where $\textbf{v}_a$ and $\textbf{W}_a$ are weighted matrices to be learned in the training process. They can be implemented as dense layers using keras. For a python implementation of the Bahnadau attention mechanism one can be refered to the following <a href=https://www.kaggle.com/code/alesc07/attention-assignment>Notebook</a>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>BahdanauAttention</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>units</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>BahdanauAttention</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>        
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>W1</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>W2</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>V</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>,</span> <span class=n>values</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>query_with_time_axis</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>expand_dims</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># BAHDANAU Additive</span>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>V</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>tanh</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>W1</span><span class=p>(</span><span class=n>query_with_time_axis</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>W2</span><span class=p>(</span><span class=n>values</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># attention_weights shape == (batch_size, max_length, 1)</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_weights</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>score</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># context_vector shape after sum == (batch_size, hidden_size)</span>
</span></span><span class=line><span class=cl>        <span class=n>context_vector</span> <span class=o>=</span> <span class=n>attention_weights</span> <span class=o>*</span> <span class=n>values</span>
</span></span><span class=line><span class=cl>        <span class=n>context_vector</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_sum</span><span class=p>(</span><span class=n>context_vector</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>context_vector</span><span class=p>,</span> <span class=n>attention_weights</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=luong-attention>Luong attention:<a hidden class=anchor aria-hidden=true href=#luong-attention>#</a></h2><p><strong>Luong attention</strong>, introduced in a 2015 <a href=https://arxiv.org/pdf/1508.04025.pdf>paper</a> by Minh-Thang Luong et al., is a variant of Bahdanau attention that uses different similarity measures to calculate the attention weights.</p><p>One common variant is <strong>dot-product attention</strong>, which calculates the attention weights as the dot product between the current state of the model and each element in the input sequence. That is,</p><p>$$ \text{score}(\textbf{h}_t, \bar{\textbf{h}}_i) = \textbf{h}_t^T \cdot \bar{\textbf{h}}_i $$</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>LuongDotAttention</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>LuongDotAttention</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>,</span> <span class=n>values</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>query_with_time_axis</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>expand_dims</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>values_transposed</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>values</span><span class=p>,</span> <span class=n>perm</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># LUONG Dot-product</span>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>query_with_time_axis</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                                       <span class=n>values_transposed</span><span class=p>),</span> <span class=n>perm</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># attention_weights shape == (batch_size, max_length, 1)</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_weights</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>score</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># context_vector shape after sum == (batch_size, hidden_size)</span>
</span></span><span class=line><span class=cl>        <span class=n>context_vector</span> <span class=o>=</span> <span class=n>attention_weights</span> <span class=o>*</span> <span class=n>values</span>
</span></span><span class=line><span class=cl>        <span class=n>context_vector</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_sum</span><span class=p>(</span><span class=n>context_vector</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>context_vector</span><span class=p>,</span> <span class=n>attention_weights</span>
</span></span></code></pre></td></tr></table></div></div><p>Another variant is <strong>general attention</strong>, which implements the attention weights $\textbf{W}_a$ using a general linear function.</p><p>$$ \text{score}(\textbf{h}_t, \bar{\textbf{h}}_i) = \textbf{h}_t^T \cdot \textbf{W}_a \cdot \bar{\textbf{h}}_i $$</p><p>Such $\textbf{W}_a$ matrix is also to be learned during the training process. For a python implementation of the Luong attention mechanisms one can be refered to the following <a href=https://www.kaggle.com/code/alesc07/attention-assignment>Notebook</a>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>LuongGeneralAttention</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>units</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>LuongGeneralAttention</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>W</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>,</span> <span class=n>values</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>query_with_time_axis</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>expand_dims</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>values_transposed</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>values</span><span class=p>,</span> <span class=n>perm</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># LUONG General</span>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>W</span><span class=p>(</span><span class=n>query_with_time_axis</span><span class=p>),</span> 
</span></span><span class=line><span class=cl>                                       <span class=n>values_transposed</span><span class=p>),</span> <span class=n>perm</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># attention_weights shape == (batch_size, max_length, 1)</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_weights</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>score</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># context_vector shape after sum == (batch_size, hidden_size)</span>
</span></span><span class=line><span class=cl>        <span class=n>context_vector</span> <span class=o>=</span> <span class=n>attention_weights</span> <span class=o>*</span> <span class=n>values</span>
</span></span><span class=line><span class=cl>        <span class=n>context_vector</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_sum</span><span class=p>(</span><span class=n>context_vector</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>context_vector</span><span class=p>,</span> <span class=n>attention_weights</span>
<<<<<<< HEAD
</span></span></code></pre></td></tr></table></div></div><h2 id=limitations-of-attention-mechanisms>Limitations of attention mechanisms:<a hidden class=anchor aria-hidden=true href=#limitations-of-attention-mechanisms>#</a></h2><p>While attention mechanisms have been shown to be effective in many NLP tasks, they do have some limitations:</p><ol><li><p><strong>Computational intensity:</strong> Attention mechanisms can be computationally intensive, especially for large input sequences. This can make them difficult to train and use in practice, for instance on large datasets.</p></li><li><p><strong>Limited ability to capture long-range dependencies:</strong> Attention mechanisms can struggle to accurately capture long-range dependencies in the input, as they only consider the current state of the model and the input elements when calculating the attention weights. This can lead to suboptimal performance on tasks that require the model to consider the relationship between distant elements in the input sequence.</p></li><li><p><strong>Limited interpretability:</strong> Attention mechanisms can be difficult to interpret, as it is often not clear how the attention weights are being calculated or how they are influencing the model&rsquo;s predictions. This can make it difficult to understand the decision-making process of the model and debug any errors.</p></li><li><p><strong>Limited generalizability:</strong> Attention mechanisms may not generalize well to new data, as they are trained on specific datasets and may not be able to adapt to different input distributions.</p></li></ol><h2 id=conclusion>Conclusion:<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Overall, attention mechanisms have many strengths and have been shown to be effective in many NLP tasks. However, it is important to be aware of their limitations and to carefully consider whether they are the best approach for a particular task. Having said so, attention mechanisms are an active area of research in NLP and there are many potential directions for future development. These developments could lead to more efficient, accurate, interpretable, and generalizable attention mechanisms, which could further improve the performance of NLP models and enable them to solve more complex tasks.</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/attention-mechanisms/>Attention Mechanisms</a></li><li><a href=http://localhost:1313/tags/natural-language-processing/>Natural Language Processing</a></li><li><a href=http://localhost:1313/tags/deep-learning/>Deep Learning</a></li><li><a href=http://localhost:1313/tags/machine-translation/>Machine Translation</a></li><li><a href=http://localhost:1313/tags/ai/>AI</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/papers/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/><span class=title>« Prev</span><br><span>Notes on Deep Unsupervised Learning Using Nonequilibrium Thermodynamics</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on x" href="https://x.com/intent/tweet/?text=Attention%20and%20Context%20based%20Embeddings&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2farticles%2fattention-mechanisms%2f&amp;hashtags=AttentionMechanisms%2cNaturalLanguageProcessing%2cDeepLearning%2cMachineTranslation%2cAI"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2farticles%2fattention-mechanisms%2f&amp;title=Attention%20and%20Context%20based%20Embeddings&amp;summary=Attention%20and%20Context%20based%20Embeddings&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2farticles%2fattention-mechanisms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2farticles%2fattention-mechanisms%2f&title=Attention%20and%20Context%20based%20Embeddings"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2farticles%2fattention-mechanisms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on whatsapp" href="https://api.whatsapp.com/send?text=Attention%20and%20Context%20based%20Embeddings%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2farticles%2fattention-mechanisms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on telegram" href="https://telegram.me/share/url?text=Attention%20and%20Context%20based%20Embeddings&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2farticles%2fattention-mechanisms%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on ycombinator" href="https://news.ycombinator.com/submitlink?t=Attention%20and%20Context%20based%20Embeddings&u=http%3a%2f%2flocalhost%3a1313%2fposts%2farticles%2fattention-mechanisms%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Àlex</a></span> ·
=======
</span></span></code></pre></td></tr></table></div></div><h2 id=limitations-of-attention-mechanisms>Limitations of attention mechanisms:<a hidden class=anchor aria-hidden=true href=#limitations-of-attention-mechanisms>#</a></h2><p>While attention mechanisms have been shown to be effective in many NLP tasks, they do have some limitations:</p><ol><li><p><strong>Computational intensity:</strong> Attention mechanisms can be computationally intensive, especially for large input sequences. This can make them difficult to train and use in practice, for instance on large datasets.</p></li><li><p><strong>Limited ability to capture long-range dependencies:</strong> Attention mechanisms can struggle to accurately capture long-range dependencies in the input, as they only consider the current state of the model and the input elements when calculating the attention weights. This can lead to suboptimal performance on tasks that require the model to consider the relationship between distant elements in the input sequence.</p></li><li><p><strong>Limited interpretability:</strong> Attention mechanisms can be difficult to interpret, as it is often not clear how the attention weights are being calculated or how they are influencing the model&rsquo;s predictions. This can make it difficult to understand the decision-making process of the model and debug any errors.</p></li><li><p><strong>Limited generalizability:</strong> Attention mechanisms may not generalize well to new data, as they are trained on specific datasets and may not be able to adapt to different input distributions.</p></li></ol><h2 id=conclusion>Conclusion:<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Overall, attention mechanisms have many strengths and have been shown to be effective in many NLP tasks. However, it is important to be aware of their limitations and to carefully consider whether they are the best approach for a particular task. Having said so, attention mechanisms are an active area of research in NLP and there are many potential directions for future development. These developments could lead to more efficient, accurate, interpretable, and generalizable attention mechanisms, which could further improve the performance of NLP models and enable them to solve more complex tasks.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://alex-pv01.github.io/tags/attention-mechanisms/>Attention Mechanisms</a></li><li><a href=https://alex-pv01.github.io/tags/natural-language-processing/>Natural Language Processing</a></li><li><a href=https://alex-pv01.github.io/tags/deep-learning/>Deep Learning</a></li><li><a href=https://alex-pv01.github.io/tags/machine-translation/>Machine Translation</a></li><li><a href=https://alex-pv01.github.io/tags/ai/>AI</a></li></ul><nav class=paginav><a class=prev href=https://alex-pv01.github.io/posts/papers/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/><span class=title>« Prev</span><br><span>Notes on Deep Unsupervised Learning Using Nonequilibrium Thermodynamics</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on twitter" href="https://twitter.com/intent/tweet/?text=Attention%20and%20Context%20based%20Embeddings&amp;url=https%3a%2f%2falex-pv01.github.io%2fposts%2farticles%2fattention-mechanisms%2f&amp;hashtags=AttentionMechanisms%2cNaturalLanguageProcessing%2cDeepLearning%2cMachineTranslation%2cAI"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2falex-pv01.github.io%2fposts%2farticles%2fattention-mechanisms%2f&amp;title=Attention%20and%20Context%20based%20Embeddings&amp;summary=Attention%20and%20Context%20based%20Embeddings&amp;source=https%3a%2f%2falex-pv01.github.io%2fposts%2farticles%2fattention-mechanisms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on reddit" href="https://reddit.com/submit?url=https%3a%2f%2falex-pv01.github.io%2fposts%2farticles%2fattention-mechanisms%2f&title=Attention%20and%20Context%20based%20Embeddings"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2falex-pv01.github.io%2fposts%2farticles%2fattention-mechanisms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on whatsapp" href="https://api.whatsapp.com/send?text=Attention%20and%20Context%20based%20Embeddings%20-%20https%3a%2f%2falex-pv01.github.io%2fposts%2farticles%2fattention-mechanisms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on telegram" href="https://telegram.me/share/url?text=Attention%20and%20Context%20based%20Embeddings&amp;url=https%3a%2f%2falex-pv01.github.io%2fposts%2farticles%2fattention-mechanisms%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Attention and Context based Embeddings on ycombinator" href="https://news.ycombinator.com/submitlink?t=Attention%20and%20Context%20based%20Embeddings&u=https%3a%2f%2falex-pv01.github.io%2fposts%2farticles%2fattention-mechanisms%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://alex-pv01.github.io/>Àlex</a></span>
>>>>>>> 3e41910ec3b37fbf49862f5d6edb1c57ce5467db
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>